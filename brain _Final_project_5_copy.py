# -*- coding: utf-8 -*-
"""final_Project 5 - Copy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16-_S17HKl1AQxtFvJ02eqmE7Wnj4GpDk
"""

from google.colab import drive
drive.mount('/content/drive')

!ls /content/drive/MyDrive/data

!ls /content/drive/MyDrive/data/Tumour

!cp -r "/content/drive/MyDrive/data/Tumour/" /content/data/

!ls /content/data

!ls /content/data/Tumour

"""## STEP 1 - DATASET EXPLORATION"""

import os
import matplotlib.pyplot as plt
from PIL import Image

train_path = "/content/data/Tumour/train"

# ✅ Step 1: Select ONLY folders (ignore files like _classes.csv)
classes = [
    d for d in os.listdir(train_path)
    if os.path.isdir(os.path.join(train_path, d))
]

print("Classes:", classes)

# ✅ Step 2: Count images in each class
counts = {}
for cls in classes:
    class_path = os.path.join(train_path, cls)
    images = [
        f for f in os.listdir(class_path)
        if f.lower().endswith(('.jpg', '.png', '.jpeg'))
    ]
    counts[cls] = len(images)

print("Class Distribution:", counts)

# ✅ Step 3: Show one sample image per class
plt.figure(figsize=(12, 4))

for i, cls in enumerate(classes):
    class_path = os.path.join(train_path, cls)
    img_name = next(
        f for f in os.listdir(class_path)
        if f.lower().endswith(('.jpg', '.png', '.jpeg'))
    )

    img = Image.open(os.path.join(class_path, img_name))

    plt.subplot(1, len(classes), i + 1)
    plt.imshow(img)
    plt.title(cls)
    plt.axis("off")

plt.show()

"""##  STEP 2 - DATA PREPROCESSING"""

import tensorflow as tf
from tensorflow.keras import layers

# -----------------------------
# Step 2A: Basic parameters
# -----------------------------
IMG_SIZE = (224, 224)
BATCH_SIZE = 32
SEED = 42

train_dir = "/content/data/Tumour/train"
val_dir   = "/content/data/Tumour/val"
test_dir  = "/content/data/Tumour/test"

# -----------------------------
# Step 2B: Load datasets
# -----------------------------
train_ds = tf.keras.utils.image_dataset_from_directory(
    train_dir,
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    shuffle=True,
    seed=SEED
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    val_dir,
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    shuffle=False
)

test_ds = tf.keras.utils.image_dataset_from_directory(
    test_dir,
    image_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    shuffle=False
)

# -----------------------------
# Step 2C: Get class names
# -----------------------------
class_names = train_ds.class_names
print("Class Names:", class_names)

# -----------------------------
# Step 2D: Normalize pixel values
# -----------------------------
normalization_layer = layers.Rescaling(1./255)

train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))
val_ds   = val_ds.map(lambda x, y: (normalization_layer(x), y))
test_ds  = test_ds.map(lambda x, y: (normalization_layer(x), y))

# -----------------------------
# Step 2E: Improve performance
# -----------------------------
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)
val_ds   = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
test_ds  = test_ds.cache().prefetch(buffer_size=AUTOTUNE)

"""## STEP 3 — DATA AUGMENTATION"""

import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras import layers

# ----------------------------------
# STEP 3A: Define Data Augmentation
# ----------------------------------
data_augmentation = tf.keras.Sequential(
    [
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.1),
        layers.RandomContrast(0.1),
    ],
    name="data_augmentation"
)

# ----------------------------------
# STEP 3B: Apply augmentation ONLY to training dataset
# ----------------------------------
train_ds = train_ds.map(
    lambda x, y: (data_augmentation(x, training=True), y),
    num_parallel_calls=tf.data.AUTOTUNE
)

# ----------------------------------
# STEP 3C: Visualize augmented images (safe & clean)
# ----------------------------------
raw_train_ds = tf.keras.utils.image_dataset_from_directory(
    "/content/data/Tumour/train",
    image_size=(224, 224),
    batch_size=1,
    shuffle=True
)

for images, labels in raw_train_ds.take(1):
    plt.figure(figsize=(10, 5))
    for i in range(6):
        aug_img = data_augmentation(images, training=True)[0]
        aug_img = tf.clip_by_value(aug_img, 0.0, 255.0) / 255.0
        plt.subplot(2, 3, i + 1)
        plt.imshow(aug_img)
        plt.axis("off")
    plt.show()

"""## STEP 4 —  MODEL BUILDING CUSTOM CNN MODEL"""

import tensorflow as tf
from tensorflow.keras import layers, models

NUM_CLASSES = 4   # change if your dataset has different classes
IMG_SIZE = (224, 224, 3)

def build_custom_cnn():
    model = models.Sequential([
        layers.Input(shape=IMG_SIZE),

        layers.Conv2D(32, (3,3), activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(),

        layers.Conv2D(64, (3,3), activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(),

        layers.Conv2D(128, (3,3), activation='relu'),
        layers.BatchNormalization(),
        layers.MaxPooling2D(),

        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(NUM_CLASSES, activation='softmax')
    ])

    return model

custom_cnn_model = build_custom_cnn()

custom_cnn_model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

custom_cnn_model.summary()

"""## STEP 5 - TRANSFER LEARNING"""

import tensorflow as tf
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.layers import (
    Input,
    GlobalAveragePooling2D,
    BatchNormalization,
    Dense,
    Dropout
)
from tensorflow.keras.models import Model

NUM_CLASSES = 4

# -------------------------------
# Load Pretrained Model
# -------------------------------
base_model = EfficientNetB0(
    weights="imagenet",
    include_top=False,
    input_shape=(224, 224, 3)
)

base_model.trainable = False

# -------------------------------
# Build Functional Model
# -------------------------------
inputs = Input(shape=(224, 224, 3))
x = base_model(inputs, training=False)
x = GlobalAveragePooling2D()(x)
x = BatchNormalization()(x)
x = Dense(128, activation="relu")(x)
x = Dropout(0.5)(x)
outputs = Dense(NUM_CLASSES, activation="softmax")(x)

transfer_model = Model(inputs, outputs)

# -------------------------------
# Compile (ONLY ONCE)
# -------------------------------
transfer_model.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

transfer_model.summary()

"""## STEP 6 — MODEL TRAINING"""

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

early_stop = EarlyStopping(
    monitor="val_loss",
    patience=5,
    restore_best_weights=True
)

import tensorflow as tf
import numpy as np
import random

tf.random.set_seed(42)
np.random.seed(42)
random.seed(42)

"""### 6.1 TRAINING — CUSTOM CNN"""

from tensorflow.keras.callbacks import ModelCheckpoint

checkpoint_cnn = ModelCheckpoint(
    "custom_cnn_best.keras",
    monitor="val_loss",
    save_best_only=True,
    verbose=1
)

history_custom_cnn = custom_cnn_model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=20,
    callbacks=[checkpoint_cnn],
    verbose=1
)

"""### 6.2 TRAINING — TRANSFER LEARNING MODEL"""

# Save best Transfer Learning model
checkpoint_tl = ModelCheckpoint(
    "transfer_learning_best.keras",
    monitor="val_loss",
    save_best_only=True,
    verbose=1
)

# Train Transfer Learning model
history_transfer = transfer_model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=20,                # ✅ WILL COMPLETE ALL 20
    callbacks=[checkpoint_tl],
    verbose=1
)

print("Custom CNN Final Accuracy:", history_custom_cnn.history["accuracy"][-1])
print("Custom CNN Final Val Accuracy:", history_custom_cnn.history["val_accuracy"][-1])

print("Transfer Learning Final Accuracy:", history_transfer.history["accuracy"][-1])
print("Transfer Learning Final Val Accuracy:", history_transfer.history["val_accuracy"][-1])

"""## 7 MODEL EVALUATION"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.metrics import classification_report, confusion_matrix

from tensorflow.keras.models import load_model

# Load best trained models
custom_cnn_model = load_model("custom_cnn_best.keras")
transfer_model = load_model("transfer_learning_best.keras")

# Get true labels from test dataset
y_true = np.concatenate([y.numpy() for x, y in test_ds])

# Custom CNN predictions
y_pred_cnn = custom_cnn_model.predict(test_ds)
y_pred_cnn = np.argmax(y_pred_cnn, axis=1)

# Transfer Learning predictions
y_pred_tl = transfer_model.predict(test_ds)
y_pred_tl = np.argmax(y_pred_tl, axis=1)

"""### Classification Report"""

print("Custom CNN Classification Report:\n")
print(classification_report(y_true, y_pred_cnn, target_names=class_names))

from sklearn.metrics import classification_report

print("Transfer Learning Classification Report:\n")
print(
    classification_report(
        y_true,
        y_pred_tl,
        target_names=class_names,
        zero_division=0   # ✅ FIXES WARNING
    )
)

"""### Confusion Matrix"""

cm_cnn = confusion_matrix(y_true, y_pred_cnn)

plt.figure(figsize=(6,5))
sns.heatmap(cm_cnn, annot=True, fmt="d", cmap="Blues",
            xticklabels=class_names,
            yticklabels=class_names)
plt.title("Confusion Matrix – Custom CNN")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

cm_tl = confusion_matrix(y_true, y_pred_tl)

plt.figure(figsize=(6,5))
sns.heatmap(cm_tl, annot=True, fmt="d", cmap="Greens",
            xticklabels=class_names,
            yticklabels=class_names)
plt.title("Confusion Matrix – Transfer Learning")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""### Training History Evaluation"""

#Accuarcy plot
plt.figure(figsize=(10,4))

plt.subplot(1,2,1)
plt.plot(history_custom_cnn.history['accuracy'], label='CNN Train')
plt.plot(history_custom_cnn.history['val_accuracy'], label='CNN Val')
plt.plot(history_transfer.history['accuracy'], label='TL Train')
plt.plot(history_transfer.history['val_accuracy'], label='TL Val')
plt.title("Model Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()

#Loss plot
plt.subplot(1,2,2)
plt.plot(history_custom_cnn.history['loss'], label='CNN Train')
plt.plot(history_custom_cnn.history['val_loss'], label='CNN Val')
plt.plot(history_transfer.history['loss'], label='TL Train')
plt.plot(history_transfer.history['val_loss'], label='TL Val')
plt.title("Model Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()

plt.show()

"""## 8 MODEL COMPARISON"""

#STEP 1: CALCULATE TEST ACCURACY FOR BOTH MODELS
# Evaluate models on test dataset
cnn_test_loss, cnn_test_acc = custom_cnn_model.evaluate(test_ds, verbose=0)
tl_test_loss, tl_test_acc = transfer_model.evaluate(test_ds, verbose=0)

print(f"Custom CNN Test Accuracy: {cnn_test_acc:.4f}")
print(f"Transfer Learning Test Accuracy: {tl_test_acc:.4f}")

# CREATE COMPARISON TABLE
import pandas as pd

comparison_df = pd.DataFrame({
    "Model": ["Custom CNN", "Transfer Learning (EfficientNetB0)"],
    "Test Accuracy": [cnn_test_acc, tl_test_acc],
    "Training Epochs": [20, 20],
    "Model Size": ["Small", "Large (Pretrained)"],
    "Training Time": ["Longer", "Faster"],
    "Generalization": ["Moderate", "Better"]
})

comparison_df

#VISUAL COMPARISON (BAR CHART)
import matplotlib.pyplot as plt

models = ["Custom CNN", "Transfer Learning"]
accuracies = [cnn_test_acc, tl_test_acc]

plt.figure(figsize=(6,4))
plt.bar(models, accuracies)
plt.title("Model Accuracy Comparison")
plt.ylabel("Accuracy")
plt.ylim(0, 1)
plt.show()

#FINAL MODEL SELECTION LOGIC
best_model = "Transfer Learning" if tl_test_acc > cnn_test_acc else "Custom CNN"
print("Best Model for Deployment:", best_model)